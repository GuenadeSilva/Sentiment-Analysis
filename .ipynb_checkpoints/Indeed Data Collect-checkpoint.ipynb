{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indeed Scrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indeed Company Reviews Scrapper\n",
    "\n",
    "The way the links work in this website makes it easier to scrape the data as it loops by 20 steps\n",
    "so it's easy to set it up in a for range and counting 20 steps and there's no need to use for example clicks\n",
    "and the data is already all visible in the html \n",
    "The link is also dynamic and allows to exchange the companies via the link so the company was made as variable\n",
    "\n",
    "\n",
    "The website reviews are stored in a general container, if we try to scrape directly  the instead of going\n",
    "inside of the container the we're getting empty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Necessary Librabries\n",
    "import time\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the argument to make it not visible\n",
    "options = Options()\n",
    "options.add_argument('--headless')\n",
    "#options.add_argument('--disable-gpu')  # this was necessary in windows/chrome\n",
    "options.add_argument(\"--disable-blink-features\") # avoid Robot detection\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open Chrome with Selenium\n",
    "browser = webdriver.Chrome('E:\\Documentos\\chromedriver.exe', options = options)  # Optional argument, if not specified will search path.\n",
    "\n",
    "\n",
    "# Open Firefox with Selenium (unmark to run with firefox)\n",
    "#binary = FirefoxBinary('/Applications/Firefox.app/Contents/MacOS/firefox-bin')  # replace the Firexfox path with the one on your computer\n",
    "#browser = webdriver.Firefox(firefox_binary=binary, options=options)\n",
    "#browser = webdriver.Firefox(options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a DataFrame to store the data\n",
    "extracted_reviews = pd.DataFrame({'review title': pd.Series([], dtype='string'),\n",
    "                                    'review':pd.Series([], dtype='string'),\n",
    "                                    'pros':pd.Series([], dtype='string'),\n",
    "                                    'cons':pd.Series([], dtype='string'),\n",
    "                                    'date':pd.Series([], dtype='string'),\n",
    "                                    'job':pd.Series([], dtype='string'),\n",
    "                                    'location':pd.Series([], dtype='string'),\n",
    "                                    'rating':pd.Series([], dtype='float')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Indeed_Scrapper(company,country,loops,extracted_reviews):\n",
    "    print('Pulling Reviews for ',company)\n",
    "    run = 0\n",
    "\n",
    "    for i in range(0,loops*20,20):\n",
    "        try:\n",
    "            #The link select has all the countries and the language selected was english\n",
    "            link = (f\"https://www.indeed.com/cmp/{company}/reviews?fcountry={country}&start={i}&lang=en\") \n",
    "            browser.get(link)\n",
    "            time.sleep(5)\n",
    "            html_source = browser.page_source\n",
    "            browser.quit()\n",
    "            soup = BeautifulSoup(html_source,\"html.parser\")\n",
    "            #browser.quit()\n",
    "        except:\n",
    "            print(\"Link didn't work\")\n",
    "        \n",
    "        try:\n",
    "            # Reviews are divided by containers and not all of them have the same attributes for we're scrapping per container\n",
    "            data = soup.find('div',{\"id\": 'cmp-container'})\n",
    "            reviews = data.find_all(class_ = \"cmp-Review-container\")\n",
    "            for x in reviews:\n",
    "                #Pull the title\n",
    "                title = x.find(attrs = {'class':'cmp-Review-title'})\n",
    "                \n",
    "                #Pull the review content\n",
    "                review = x.find('div', {'class': 'cmp-Review-text'})\n",
    "                \n",
    "                #Not all reviews have the pros and cons (but if one exists both do)\n",
    "                try:\n",
    "                    pros = x.find(attrs = {'class':'cmp-ReviewProsCons-prosText'}).find(attrs = {'class': 'cmp-NewLineToBr-text'}).get_text()\n",
    "                    cons = x.find(attrs = {'class':'cmp-ReviewProsCons-consText'}).find(attrs = {'class': 'cmp-NewLineToBr-text'}).get_text()\n",
    "                except:\n",
    "                    pros,cons = None,None\n",
    "                    \n",
    "                # Pull the Review Date\n",
    "                rev_date = x.find(attrs = {'class':'cmp-Review-author'})\n",
    "                \n",
    "                # Pull the Job title(not always present)\n",
    "                try:\n",
    "                    job = x.find('a', {'class':'cmp-ReviewAuthor-link'}).text\n",
    "                except:\n",
    "                    job = None\n",
    "                    \n",
    "                #Pull the location\n",
    "                location = x.find(attrs = {'class':'cmp-Review-author'})\n",
    "                \n",
    "                # Pull the rating given by the reviwer\n",
    "                rating = x.find(attrs = {'class':'cmp-ReviewRating-text'})\n",
    "                \n",
    "                # Save the data to the DataFrame and make the necessary changes to the text\n",
    "                extracted_reviews = extracted_reviews.append({'review title': title.text,\n",
    "                                                          'review': review.text,\n",
    "                                                          'pros': pros,\n",
    "                                                          'cons': cons,\n",
    "                                                          'date': rev_date.text.split(\"-\")[-1],\n",
    "                                                          'job': job,\n",
    "                                                          'location': location.text.split(\"-\")[-2],\n",
    "                                                          'rating': rating.text\n",
    "                                                          }, ignore_index=True)\n",
    "                print(run)\n",
    "                run += 1\n",
    "                time.sleep(random.randint(1, 10))\n",
    "        except:\n",
    "            print(\"Something went wrong! Try another time..\")\n",
    "            return[]\n",
    "    \n",
    "    #Convert the reviews as float \n",
    "    extracted_reviews['rating']= [x.replace(\",\",\".\") for x in extracted_reviews['rating']]   \n",
    "   \n",
    "    #Save to excel file\n",
    "    extracted_reviews.to_excel(\"Mcdonald's Reviews.xlsx\")\n",
    "    \n",
    "    print(\"Reviews Saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulling Reviews for  Mcdonald's\n",
      "Link didn't work\n"
     ]
    }
   ],
   "source": [
    "Indeed_Scrapper(\"Mcdonald's\",\"GB\",2,extracted_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
